{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from dash import Dash, dcc, html, Input, Output, State, callback\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tat = pd.read_csv(\"../data/lucas_organic_carbon_training_and_test_data_NEW.csv\")\n",
    "targets = pd.read_csv(\"../data/lucas_organic_carbon_target.csv\")\n",
    "\n",
    "# TODO: scale data\n",
    "# scaler = StandardScaler()\n",
    "# scaled_data = scaler.fit_transform(df)\n",
    "# scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "# scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(input_tat, start, end):\n",
    "    numeric_columns = pd.to_numeric(input_tat.columns, errors='coerce')\n",
    "\n",
    "    # Filter columns based on the interval\n",
    "    filtered_columns = input_tat.columns[(numeric_columns >= start) & (numeric_columns <= end)]\n",
    "\n",
    "    # Create a new DataFrame with only the filtered columns\n",
    "    input_tat = input_tat[filtered_columns]\n",
    "\n",
    "    tat_train, tat_test, targets_train, targets_test = train_test_split(input_tat, targets, test_size=0.33, random_state=42)\n",
    "\n",
    "    targets_train = targets_train.values.ravel()\n",
    "    targets_test = targets_test.values.ravel()\n",
    "\n",
    "    feature_names = input_tat.columns.to_list()\n",
    "    return tat_train, tat_test, targets_train, targets_test, feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def save_explanation(model, new_model_name, tat_train, fnames):\n",
    "    # TODO: if model ist Linear Regression:\n",
    "    explainer = shap.Explainer(model, tat_train, feature_names=fnames)\n",
    "\n",
    "    # TODO: if model ist XGBoost oder Random Forest\n",
    "    explainer = shap.TreeExplainer(model, feature_names=fnames)\n",
    "\n",
    "    explanation = explainer(tat_train)\n",
    "\n",
    "    file_path = f\"../shapley_values/saved_values/{new_model_name}-saved_values\"\n",
    "    joblib.dump(explanation, file_path)\n",
    "    return\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    ('XGBoost', joblib.load('../models/best_model_xgboost.pkl'), 'xgboost', joblib.load('../shapley-values/saved_values/xgboost-shapley_values')),\n",
    "    ('Random Forest', joblib.load('../models/best_model_random_forest.pkl'), 'random_forest', joblib.load('../shapley-values/saved_values/randomforest-shapley_values')),\n",
    "    ('Logistic Regression', joblib.load('../models/logreg.pkl'), 'logic_regression', joblib.load('../shapley-values/saved_values/logreg_shapley_values'))\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_model(model_entry, tat, start, end):\n",
    "    tat_train, tat_test, targets_train, targets_test, feature_names = get_data(tat, start, end)\n",
    "\n",
    "    new_model_name = f\"{model_entry[0]} {start}-{end}\"\n",
    "    print(f\"building {new_model_name}\")\n",
    "    match model_entry[2]:\n",
    "        case 'logic_regression':\n",
    "            model = LogisticRegression(random_state=0)\n",
    "            model.fit(tat_train, targets_train)\n",
    "\n",
    "            explainer = shap.Explainer(model, tat_train, feature_names=feature_names)\n",
    "            explanation = explainer(tat_train)\n",
    "            # file_path = f\"../shapley-values/saved_values/{new_model_name}-saved_values\"\n",
    "            # joblib.dump(explanation, file_path)\n",
    "            # model_list.append((new_model_name, model, 'logic_regression'))\n",
    "            model_list.append((new_model_name, model, 'logic_regression', explanation))\n",
    "            \n",
    "        case 'xgboost':\n",
    "            use_gpu = False\n",
    "            label_encoder = LabelEncoder()\n",
    "            targets_train = label_encoder.fit_transform(targets_train)\n",
    "            print(targets_train)\n",
    "\n",
    "            if use_gpu:\n",
    "                model = xgb.XGBClassifier(learning_rate=0.02, n_estimators=10, objective='multi:softmax',\n",
    "                                        num_class=len(pd.unique(targets_train)), tree_method=\"hist\", device=\"cuda\")\n",
    "            else:\n",
    "                model = xgb.XGBClassifier(learning_rate=0.02, n_estimators=10, objective='multi:softmax',\n",
    "                                        num_class=len(pd.unique(targets_train)))\n",
    "\n",
    "            print(tat_train)\n",
    "            model.fit(tat_train, targets_train)\n",
    "\n",
    "            explainer = shap.TreeExplainer(model, feature_names=feature_names)\n",
    "            explanation = explainer(tat_train)\n",
    "            # file_path = f\"../shapley-values/saved_values/{new_model_name}-saved_value.json\"\n",
    "            # joblib.dump(explanation, file_path)\n",
    "            # model_list.append((new_model_name, model, 'xgboost'))\n",
    "            model_list.append((new_model_name, model, 'xgboost', explanation))\n",
    "\n",
    "        case 'random_forest':\n",
    "            model = RandomForestClassifier(n_estimators=100, random_state=42, verbose=2, n_jobs=-1)\n",
    "            print('start training')\n",
    "            print(tat_train.shape)\n",
    "            print(targets_train.shape)\n",
    "            model.fit(tat_train, targets_train)\n",
    "            print('Finished training')\n",
    "\n",
    "            print('the shap values will be generated now')\n",
    "            explainer = shap.TreeExplainer(model, feature_names=feature_names)\n",
    "            explanation = explainer(tat_train)\n",
    "            # file_path = f\"../shapley-values/saved_values/{new_model_name}-saved_value.json\"\n",
    "            # joblib.dump(explanation, file_path)\n",
    "            # model_list.append((new_model_name, model, 'random_forest'))\n",
    "            model_list.append((new_model_name, model, 'random_forest', explanation))\n",
    "        case _:\n",
    "            raise Exception('Model is not found.')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_by_name(model_list, model_name):\n",
    "    for model_entry in model_list:\n",
    "        if model_name.lower() in model_entry[0].lower():\n",
    "            return model_entry\n",
    "    return None  # Model not found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Dash(__name__)\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Retraining\"),\n",
    "    dcc.Dropdown([t[0] for t in model_list], placeholder='Select Model', id='dropdown'),\n",
    "    dcc.Input(type='number', placeholder='Enter Start', id='input_start'),\n",
    "    dcc.Input(type='number', placeholder='Enter End', id='input_end'),\n",
    "    html.Br(),  \n",
    "    html.Button('Retrain', id='btn_retrain'),\n",
    "    html.Div(id='dd-output-container')\n",
    "])\n",
    "\n",
    "@callback(\n",
    "    Output('dropdown', 'options'),\n",
    "    State('dropdown', 'value'),\n",
    "    State('input_start', 'value'),\n",
    "    State('input_end', 'value'),\n",
    "    Input('btn_retrain', 'n_clicks')\n",
    ")\n",
    "def retrain_model(model_name, start, end, n_clicks):\n",
    "    if n_clicks is None:\n",
    "        return dash.no_update  # Do nothing if the button is not clicked\n",
    "    if model_name is None or start is None or end is None:\n",
    "        return dash.no_update  # Do nothing if not all values are provided\n",
    "    \n",
    "    model_entry = get_model_by_name(model_list, model_name)\n",
    "\n",
    "    generate_new_model(model_entry, tat, start, end)\n",
    "    print('model has been generated')\n",
    "    return [t[0] for t in model_list] # this is not really nice (from a clean code perspective) but it works \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
